## SAPG: Split and Aggregate Policy Gradients
1. 目前的on-policy的RL难以并行
2. 提出一种能并行的on-policy RL，并行地学习各个环境的policy，然后聚合
3. 是一种在线学习和连续学习的感觉
4. 复习RL后再看，放waiting list