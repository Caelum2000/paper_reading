### FlexPrefill: A CONTEXT-AWARE SPARSE ATTENTION MECHANISM FOR EFFICIENT LONG-SEQUENCE INFERENCE
1. 针对sparse attention进行优化，动态的根据输入的query对attention map 进行mask
2. realted work里有高效inference的相关文献。放waiting list, 有时间就调研一下，没时间就忽略