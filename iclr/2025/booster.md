### BOOSTER: TACKLING HARMFUL FINE-TUNING FOR LARGE LANGUAGE MODELS VIA ATTENUATING HARMFUL PERTURBATION
1. 提出了一种在LLM alignment 阶段对抗后续finetune会导致对齐失效的方法
2. 就算在align的时候用harm数据集的SGD一步的loss变化作为regularizer