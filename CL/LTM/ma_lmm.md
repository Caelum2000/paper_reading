## MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding
1. 用于视频理解
2. frame经过encoder后的embedding存到bank，然后用cross attention与后面的信息交互
3. 用到了Q-former和Query Memory Bank