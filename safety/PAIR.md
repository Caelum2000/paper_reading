## Jailbreaking Black Box Large Language Models in Twenty Queries
1. 利用一个LLM攻击另一个LLM
2. 攻击者LLM可以根据攻击是否成功，不断用CoT等去refine prompt
3. 关注一下attacker的system prompt, 是怎么让attacker不断refine的